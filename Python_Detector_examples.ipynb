{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falken20/Colaboratory-projects/blob/master/Python_Detector_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ot5ylbMj7vK"
      },
      "source": [
        "### **Detection example using mediapipe**\n",
        "\n",
        "#### **Resources**:\n",
        "\n",
        "Web: [mediapipe](https://mediapipe-studio.webapps.google.com/home)\n",
        "\n",
        "Model: [efficientdet_lite0.tflite](https://github.com/schu-lab/Tensorflow-Object-Detection/blob/main/efficientdet_lite0.tflite)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "uKTxfGlAevPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr3hS4wfkEz6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgRG4B10kHbl"
      },
      "outputs": [],
      "source": [
        "# The mediapipe object detector requires a trained model\n",
        "# More information and trained models:\n",
        "# https://developers.google.com/mediapipe/solutions/vision/object_detector/index#models\n",
        "MODEL_PATH = './trained_model/efficientdet_lite0.tflite'\n",
        "IMAGE_FILE = \"https://storage.googleapis.com/mediapipe-tasks/object_detector/cat_and_dog.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrKxQhP5kXKE"
      },
      "outputs": [],
      "source": [
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Draws bounding boxes on the input image and return it.\n",
        "    Args:\n",
        "      image: The input RGB image.\n",
        "      detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "    Returns:\n",
        "      Image with bounding boxes.\n",
        "    \"\"\"\n",
        "    for detection in detection_result.detections:\n",
        "        # Draw bounding_box\n",
        "        bbox = detection.bounding_box\n",
        "        start_point = bbox.origin_x, bbox.origin_y\n",
        "        end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "        cv2.rectangle(image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "        # Draw label and score\n",
        "        category = detection.categories[0]\n",
        "        category_name = category.category_name\n",
        "        probability = round(category.score, 2)\n",
        "        result_text = category_name + ' (' + str(probability) + ')'\n",
        "        text_location = (MARGIN + bbox.origin_x,\n",
        "                         MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "        cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                    FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BZ0VcOnkbXZ"
      },
      "outputs": [],
      "source": [
        "def detect_image() -> None:\n",
        "\n",
        "    options = vision.ObjectDetectorOptions(\n",
        "        base_options=python.BaseOptions(model_asset_path=MODEL_PATH),\n",
        "        max_results=5,\n",
        "        running_mode=vision.RunningMode.IMAGE,\n",
        "        score_threshold=0.5\n",
        "    )\n",
        "\n",
        "    detector = vision.ObjectDetector.create_from_options(options)\n",
        "\n",
        "    # Load the input image\n",
        "    image = cv2.imread(IMAGE_FILE)\n",
        "    cv2.imshow(image)\n",
        "\n",
        "    # Detect objects in the input image\n",
        "    detection_result = detector.detect(image)\n",
        "\n",
        "    # Process the detection result, in this case, visualize it\n",
        "    image_copy = np.copy(image.numpy_view())\n",
        "    annotated_image = visualize(image_copy, detection_result)\n",
        "    rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imshow(rgb_annotated_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_image(\"any_video.avi\")"
      ],
      "metadata": {
        "id": "BndPqTxje3tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-z09i7jjmaO"
      },
      "source": [
        "### **Human Detection example using cv2**\n",
        "\n",
        "#### **Resources**:\n",
        "\n",
        "Classifier: [haarcascade_fullbody.xml](https://github.com/codingforentrepreneurs/OpenCV-Python-Series/tree/master/src/cascades/data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0CYqaWjhytr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puDOJmhQh-0y"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('in.avi')\n",
        "human_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rGWLL6KkiB3v"
      },
      "outputs": [],
      "source": [
        "while (True):\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Our operations on the frame come here\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    humans = human_cascade.detectMultiScale(gray, 1.9, 1)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    for (x, y, w, h) in humans:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "    # cv2.imshow('frame', frame)\n",
        "    cv2_imshow(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Object Detection example using YOLO**\n",
        "\n",
        "#### **Resources**:\n",
        "\n",
        "Model: [yolo.h5](https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/)"
      ],
      "metadata": {
        "id": "ZWw819nVaHam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageAI\n",
        "!pip install opencv-python\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "oc42ITUxaMv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an object of the object detection class\n",
        "from imageai.Detection import ObjectDetection\n",
        "\n",
        "obj_detect = ObjectDetection()"
      ],
      "metadata": {
        "id": "BsApm1kzacxQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting and loading the YOLO model\n",
        "obj_detect.setModelTypeAsYOLOv3()\n",
        "\n",
        "obj_detect.setModelPath(\"https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\")\n",
        "obj_detect.loadModel()"
      ],
      "metadata": {
        "id": "Z0GRYPCzbOC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting objects\n",
        "detected_obj = obj_detect.detectObjectsFromImage(\n",
        "    input_image=\"any_image.jpg\",\n",
        "    output_image_path=\"./output_image.jpg\"\n",
        ")"
      ],
      "metadata": {
        "id": "8g2f2ShBiaen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying information about detected objects\n",
        "for obj in detected_obj:\n",
        "  print(obj[\"name\"] + \"-\" + str(obj[\"percentage_probability\"]),\n",
        "        obj[\"box_points\"])\n",
        "  \n",
        "# Output example\n",
        "# bicycle-97.5232720375061 [345, 60, 654, 238]\n",
        "# car-99.8550295829773 [7, 250, 778, 519]\n",
        "# person-99.85941052436829 [682, 214, 783, 476]\n",
        "# person-99.91627335548401 [76, 218, 214, 502]\n",
        "# person-68.58709454536438 [279, 276, 348, 319]"
      ],
      "metadata": {
        "id": "u1bjEcSFiyyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_Ot5ylbMj7vK",
        "Q-z09i7jjmaO"
      ],
      "authorship_tag": "ABX9TyO08q2rZ5YmK6nJr1pHDeb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}